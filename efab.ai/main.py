import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, date
import logging
from typing import List, Dict, Any
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import our modules
try:
    from src.engine.planning_engine import PlanningEngine
    from src.data.beverly_knits_live_data_integrator import BeverlyKnitsLiveDataIntegrator
    from src.core.domain.entities import *
    from src.core.domain.value_objects import *
    from src.core.use_cases import SupplyChainPlanningService, DataQualityService, ReportingService
    from src.engine.production_ml_loader import production_ml_loader
    IMPORTS_AVAILABLE = True
except ImportError as e:
    st.error(f"Import error: {e}")
    IMPORTS_AVAILABLE = False

# Configure Streamlit
st.set_page_config(
    page_title="Beverly Knits AI Supply Chain Planner",
    page_icon="üß∂",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #2E86AB;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .status-success { color: #00C851; }
    .status-warning { color: #ffbb33; }
    .status-error { color: #ff4444; }
</style>
""", unsafe_allow_html=True)

class BeverlyKnitsApp:
    def __init__(self):
        if IMPORTS_AVAILABLE:
            self.planning_service = SupplyChainPlanningService(data_path="data/live/")
            self.data_quality_service = DataQualityService(data_path="data/live/")
            self.reporting_service = ReportingService()
            self.data_integrator = BeverlyKnitsLiveDataIntegrator(data_path="data/live/")
            self.planning_engine = PlanningEngine()
        self.initialize_session_state()
    
    def initialize_session_state(self):
        """Initialize session state variables"""
        if 'data_loaded' not in st.session_state:
            st.session_state.data_loaded = False
        if 'domain_objects' not in st.session_state:
            st.session_state.domain_objects = {}
        if 'recommendations' not in st.session_state:
            st.session_state.recommendations = []
        if 'ml_forecasts' not in st.session_state:
            st.session_state.ml_forecasts = {}
        if 'ml_risk_assessment' not in st.session_state:
            st.session_state.ml_risk_assessment = {}
    
    def run(self):
        """Main application runner"""
        st.markdown('<h1 class="main-header">üß∂ Beverly Knits AI Supply Chain Planner</h1>', unsafe_allow_html=True)
        
        # Check if imports are available
        if not IMPORTS_AVAILABLE:
            st.error("‚ö†Ô∏è Some application modules could not be loaded. Running in limited mode.")
            st.info("You can still explore basic functionality and data overview.")
            self.show_simple_dashboard()
            return
        
        # Sidebar navigation
        with st.sidebar:
            st.header("Navigation")
            page = st.selectbox(
                "Select Page",
                ["Dashboard", "Data Integration", "Planning Engine", "ML Forecasting", "Recommendations", "Analytics"]
            )
        
        # Route to appropriate page
        if page == "Dashboard":
            self.show_dashboard()
        elif page == "Data Integration":
            self.show_data_integration()
        elif page == "Planning Engine":
            self.show_planning_engine()
        elif page == "ML Forecasting":
            self.show_ml_forecasting()
        elif page == "Recommendations":
            self.show_recommendations()
        elif page == "Analytics":
            self.show_analytics()
    
    def show_dashboard(self):
        """Display main dashboard"""
        st.header("üìä Executive Dashboard")
        
        # Key metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="üì¶ Materials Tracked",
                value=len(st.session_state.domain_objects.get('materials', [])),
                delta=None
            )
        
        with col2:
            st.metric(
                label="üè≠ Active Suppliers",
                value=len(st.session_state.domain_objects.get('suppliers', [])),
                delta=None
            )
        
        with col3:
            st.metric(
                label="üìã BOMs Processed",
                value=len(st.session_state.domain_objects.get('boms', [])),
                delta=None
            )
        
        with col4:
            st.metric(
                label="üí∞ Recommendations Generated",
                value=len(st.session_state.recommendations),
                delta=None
            )
        
        # ML Status section
        st.subheader("ü§ñ ML Model Status")
        
        try:
            ml_status = self.planning_engine.get_ml_model_status()
            
            if ml_status.get('ml_enabled', False):
                st.success("‚úÖ ML models are operational and ready for advanced forecasting and risk assessment")
                
                # Show model availability
                model_manager_status = ml_status.get('model_manager', {})
                risk_assessor_status = ml_status.get('risk_assessor', {})
                
                ml_col1, ml_col2 = st.columns(2)
                
                with ml_col1:
                    st.write("**Forecasting Models Available:**")
                    available_models = model_manager_status.get('available_models', {})
                    for model_name, enabled in available_models.items():
                        status_icon = "‚úÖ" if enabled else "‚ùå"
                        st.write(f"{status_icon} {model_name.upper()}")
                
                with ml_col2:
                    st.write("**Risk Assessment Models:**")
                    risk_trained = risk_assessor_status.get('risk_model_trained', False)
                    anomaly_trained = risk_assessor_status.get('anomaly_detector_trained', False)
                    
                    st.write(f"{'‚úÖ' if risk_trained else '‚ùå'} Risk Scoring Model")
                    st.write(f"{'‚úÖ' if anomaly_trained else '‚ùå'} Anomaly Detection Model")
                    
            else:
                st.warning(f"‚ö†Ô∏è ML models not fully operational: {ml_status.get('error', 'Unknown issue')}")
                
        except Exception as e:
            st.error(f"‚ùå Error checking ML status: {e}")
        
        # System status
        st.subheader("System Status")
        
        status_col1, status_col2 = st.columns(2)
        
        with status_col1:
            st.markdown("### Data Integration")
            if st.session_state.data_loaded:
                st.success("‚úÖ Data successfully loaded and integrated")
            else:
                st.warning("‚ö†Ô∏è Data not yet loaded")
        
        with status_col2:
            st.markdown("### Planning Engine")
            if st.session_state.recommendations:
                st.success("‚úÖ Planning cycle completed")
            else:
                st.info("‚ÑπÔ∏è Ready to run planning cycle")
        
        # Quick actions
        st.subheader("Quick Actions")
        
        action_col1, action_col2, action_col3, action_col4 = st.columns(4)
        
        with action_col1:
            if st.button("üîÑ Refresh Data", type="primary"):
                self.run_data_integration()
        
        with action_col2:
            if st.button("‚öôÔ∏è Run Planning", type="primary"):
                if st.session_state.data_loaded:
                    self.run_planning_engine()
                else:
                    st.error("Please load data first")
        
        with action_col3:
            if st.button("ü§ñ ML Planning", type="primary"):
                if st.session_state.data_loaded:
                    self.run_ml_enhanced_planning(30, ['arima', 'prophet'])
                else:
                    st.error("Please load data first")
        
        with action_col4:
            if st.button("üìä Generate Report", type="primary"):
                self.generate_executive_report()
    
    def show_data_integration(self):
        """Display data integration page"""
        st.header("üîó Data Integration")
        
        st.markdown("""
        This module automatically processes Beverly Knits raw data files and applies intelligent quality fixes.
        """)
        
        # File upload section
        st.subheader("üìÅ Data Files")
        
        uploaded_files = st.file_uploader(
            "Upload CSV files",
            type=['csv'],
            accept_multiple_files=True,
            help="Upload your Beverly Knits data files"
        )
        
        if uploaded_files:
            st.success(f"‚úÖ {len(uploaded_files)} files uploaded successfully")
            
            # Show file details
            for file in uploaded_files:
                with st.expander(f"üìÑ {file.name}"):
                    df = pd.read_csv(file)
                    st.dataframe(df.head())
                    st.write(f"Shape: {df.shape}")
        
        # Integration controls
        st.subheader("‚öôÔ∏è Integration Controls")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üöÄ Run Integration", type="primary"):
                self.run_data_integration()
        
        with col2:
            if st.button("üìã View Quality Report"):
                self.show_quality_report()
        
        # Integration results
        if st.session_state.data_loaded:
            st.subheader("‚úÖ Integration Results")
            
            domain_objects = st.session_state.domain_objects
            
            for key, objects in domain_objects.items():
                with st.expander(f"üìä {key.title()} ({len(objects)} items)"):
                    if objects:
                        # Convert to DataFrame for display
                        if hasattr(objects[0], 'dict'):
                            df = pd.DataFrame([obj.dict() for obj in objects[:10]])
                            st.dataframe(df)
                        else:
                            st.write(f"First item: {objects[0]}")
    
    def show_planning_engine(self):
        """Display planning engine page"""
        st.header("‚öôÔ∏è Planning Engine")
        
        st.markdown("""
        The Beverly Knits Planning Engine executes a 6-phase optimization process:
        1. **Forecast Unification** - Aggregate demand signals
        2. **BOM Explosion** - Convert SKU forecasts to material requirements
        3. **Inventory Netting** - Account for current stock levels
        4. **Procurement Optimization** - Apply EOQ and safety stock
        5. **Supplier Selection** - Choose optimal suppliers
        6. **Output Generation** - Create purchase recommendations
        """)
        
        # Configuration section
        st.subheader("‚öôÔ∏è Configuration")
        
        config_col1, config_col2 = st.columns(2)
        
        with config_col1:
            safety_stock = st.slider(
                "Safety Stock %",
                min_value=0.0,
                max_value=0.5,
                value=0.15,
                step=0.05,
                help="Safety stock buffer percentage"
            )
            
            cost_weight = st.slider(
                "Cost Weight",
                min_value=0.0,
                max_value=1.0,
                value=0.6,
                step=0.1,
                help="Weight for cost in supplier selection"
            )
        
        with config_col2:
            planning_horizon = st.number_input(
                "Planning Horizon (days)",
                min_value=30,
                max_value=365,
                value=90,
                help="Planning horizon in days"
            )
            
            max_suppliers = st.number_input(
                "Max Suppliers per Material",
                min_value=1,
                max_value=5,
                value=3,
                help="Maximum suppliers per material"
            )
        
        # Execution section
        st.subheader("üöÄ Execution")
        
        planning_col1, planning_col2 = st.columns(2)
        
        with planning_col1:
            if st.button("‚ñ∂Ô∏è Run Standard Planning", type="primary"):
                if st.session_state.data_loaded:
                    self.run_planning_engine()
                else:
                    st.error("Please load data first through the Data Integration page")
        
        with planning_col2:
            if st.button("üìä Run Sales-Based Planning", type="secondary"):
                if st.session_state.data_loaded:
                    self.run_sales_based_planning()
                else:
                    st.error("Please load data first through the Data Integration page")
        
        # Results section
        if st.session_state.recommendations:
            st.subheader("üìä Planning Results")
            
            # Summary metrics
            recommendations = st.session_state.recommendations
            total_recommendations = len(recommendations)
            total_cost = sum(rec.total_cost.amount for rec in recommendations)
            
            metric_col1, metric_col2, metric_col3 = st.columns(3)
            
            with metric_col1:
                st.metric("Total Recommendations", total_recommendations)
            
            with metric_col2:
                st.metric("Total Cost", f"${total_cost:,.2f}")
            
            with metric_col3:
                avg_urgency = sum(rec.urgency_score for rec in recommendations) / len(recommendations)
                st.metric("Average Urgency", f"{avg_urgency:.2f}")
            
            # Detailed results
            self.show_recommendations_table(recommendations)
    
    def show_ml_forecasting(self):
        """Display ML forecasting page"""
        st.header("ü§ñ ML Forecasting & Risk Assessment")
        
        st.markdown("""
        This module provides advanced machine learning capabilities for demand forecasting and supplier risk assessment.
        """)
        
        # ML Model Status
        st.subheader("üîß ML Model Status")
        
        try:
            ml_status = self.planning_engine.get_ml_model_status()
            
            if ml_status.get('ml_enabled', False):
                st.success("‚úÖ ML components are enabled and operational")
                
                # Model Manager Status
                model_manager_status = ml_status.get('model_manager', {})
                with st.expander("üìä Model Manager Status"):
                    st.json(model_manager_status)
                
                # Risk Assessor Status
                risk_assessor_status = ml_status.get('risk_assessor', {})
                with st.expander("‚ö†Ô∏è Risk Assessor Status"):
                    st.json(risk_assessor_status)
                    
            else:
                st.error(f"‚ùå ML components not available: {ml_status.get('error', 'Unknown error')}")
                
        except Exception as e:
            st.error(f"‚ùå Error checking ML status: {e}")
        
        # Forecasting Section
        st.subheader("üìà ML Demand Forecasting")
        
        st.markdown("""
        Generate advanced demand forecasts using multiple ML models:
        - **ARIMA**: Time series analysis with seasonality
        - **Prophet**: Facebook's robust forecasting model
        - **LSTM**: Deep learning neural networks
        - **XGBoost**: Gradient boosting ensemble
        """)
        
        # Forecasting configuration
        forecast_col1, forecast_col2 = st.columns(2)
        
        with forecast_col1:
            forecast_periods = st.number_input(
                "Forecast Periods",
                min_value=7,
                max_value=365,
                value=30,
                help="Number of days to forecast"
            )
            
            selected_models = st.multiselect(
                "Select Models",
                options=['arima', 'prophet', 'lstm', 'xgboost'],
                default=['arima', 'prophet'],
                help="Choose which ML models to use"
            )
        
        with forecast_col2:
            ensemble_method = st.selectbox(
                "Ensemble Method",
                options=['weighted_average', 'simple_average', 'median', 'best_model'],
                index=0,
                help="Method to combine multiple model predictions"
            )
            
            confidence_threshold = st.slider(
                "Confidence Threshold",
                min_value=0.5,
                max_value=1.0,
                value=0.8,
                step=0.05,
                help="Minimum confidence score for forecasts"
            )
        
        # Generate ML forecasts
        if st.button("üöÄ Generate ML Forecasts", type="primary"):
            if st.session_state.data_loaded:
                self.run_ml_forecasting(
                    periods=forecast_periods,
                    models=selected_models,
                    ensemble_method=ensemble_method,
                    confidence_threshold=confidence_threshold
                )
            else:
                st.error("Please load data first through the Data Integration page")
        
        # Risk Assessment Section
        st.subheader("‚ö†Ô∏è ML Risk Assessment")
        
        st.markdown("""
        Advanced supplier risk assessment using machine learning:
        - **Risk Scoring**: Multi-factor risk assessment
        - **Anomaly Detection**: Identify unusual supplier behavior
        - **Predictive Analysis**: Forecast potential supply chain disruptions
        """)
        
        # Risk assessment configuration
        risk_col1, risk_col2 = st.columns(2)
        
        with risk_col1:
            risk_threshold_low = st.slider(
                "Low Risk Threshold",
                min_value=0.0,
                max_value=1.0,
                value=0.3,
                step=0.05,
                help="Threshold for low risk classification"
            )
            
            risk_threshold_medium = st.slider(
                "Medium Risk Threshold",
                min_value=0.0,
                max_value=1.0,
                value=0.7,
                step=0.05,
                help="Threshold for medium risk classification"
            )
        
        with risk_col2:
            anomaly_contamination = st.slider(
                "Anomaly Contamination",
                min_value=0.01,
                max_value=0.5,
                value=0.1,
                step=0.01,
                help="Expected proportion of anomalies"
            )
            
            retrain_models = st.checkbox(
                "Retrain Models",
                value=False,
                help="Retrain ML models with latest data"
            )
        
        # Run risk assessment
        if st.button("üîç Run Risk Assessment", type="primary"):
            if st.session_state.data_loaded:
                self.run_ml_risk_assessment(
                    risk_threshold_low=risk_threshold_low,
                    risk_threshold_medium=risk_threshold_medium,
                    anomaly_contamination=anomaly_contamination,
                    retrain_models=retrain_models
                )
            else:
                st.error("Please load data first through the Data Integration page")
        
        # ML-Enhanced Planning
        st.subheader("üéØ ML-Enhanced Planning")
        
        st.markdown("""
        Combine ML forecasting and risk assessment for optimal planning:
        """)
        
        if st.button("‚ö° Run ML-Enhanced Planning", type="primary"):
            if st.session_state.data_loaded:
                self.run_ml_enhanced_planning(
                    periods=forecast_periods,
                    models=selected_models
                )
            else:
                st.error("Please load data first through the Data Integration page")
        
        # Display ML results if available
        if 'ml_forecasts' in st.session_state:
            st.subheader("üìä ML Forecast Results")
            self.show_ml_forecast_results(st.session_state.ml_forecasts)
        
        if 'ml_risk_assessment' in st.session_state:
            st.subheader("‚ö†Ô∏è Risk Assessment Results")
            self.show_ml_risk_results(st.session_state.ml_risk_assessment)
    
    def show_recommendations(self):
        """Display recommendations page"""
        st.header("üí∞ Procurement Recommendations")
        
        if not st.session_state.recommendations:
            st.info("No recommendations available. Please run the planning engine first.")
            return
        
        recommendations = st.session_state.recommendations
        
        # Filter controls
        st.subheader("üîç Filters")
        
        filter_col1, filter_col2, filter_col3 = st.columns(3)
        
        with filter_col1:
            risk_filter = st.multiselect(
                "Risk Level",
                options=["LOW", "MEDIUM", "HIGH"],
                default=["LOW", "MEDIUM", "HIGH"]
            )
        
        with filter_col2:
            urgency_filter = st.slider(
                "Minimum Urgency Score",
                min_value=0.0,
                max_value=1.0,
                value=0.0,
                step=0.1
            )
        
        with filter_col3:
            cost_filter = st.slider(
                "Maximum Cost",
                min_value=0.0,
                max_value=float(max(rec.total_cost.amount for rec in recommendations)),
                value=float(max(rec.total_cost.amount for rec in recommendations)),
                step=100.0
            )
        
        # Apply filters
        filtered_recommendations = [
            rec for rec in recommendations
            if (rec.risk_flag.value.upper() in risk_filter and
                rec.urgency_score >= urgency_filter and
                rec.total_cost.amount <= cost_filter)
        ]
        
        st.info(f"Showing {len(filtered_recommendations)} of {len(recommendations)} recommendations")
        
        # Display recommendations
        self.show_recommendations_table(filtered_recommendations)
        
        # Export options
        st.subheader("üì§ Export")
        
        export_col1, export_col2 = st.columns(2)
        
        with export_col1:
            if st.button("üìÑ Export to CSV"):
                self.export_recommendations_csv(filtered_recommendations)
        
        with export_col2:
            if st.button("üìä Export to Excel"):
                self.export_recommendations_excel(filtered_recommendations)
    
    def show_analytics(self):
        """Display analytics page"""
        st.header("üìä Analytics & Insights")
        
        if not st.session_state.recommendations:
            st.info("No data available for analytics. Please run the planning engine first.")
            return
        
        recommendations = st.session_state.recommendations
        
        # Cost analysis
        st.subheader("üí∞ Cost Analysis")
        
        cost_data = [
            {"Material": rec.material_id.value, "Cost": float(rec.total_cost.amount), "Risk": rec.risk_flag.value}
            for rec in recommendations
        ]
        
        cost_df = pd.DataFrame(cost_data)
        
        fig_cost = px.bar(
            cost_df,
            x="Material",
            y="Cost",
            color="Risk",
            title="Cost by Material and Risk Level",
            labels={"Cost": "Total Cost ($)"}
        )
        
        st.plotly_chart(fig_cost, use_container_width=True)
        
        # Risk distribution
        st.subheader("‚ö†Ô∏è Risk Distribution")
        
        risk_counts = cost_df['Risk'].value_counts()
        
        fig_risk = px.pie(
            values=risk_counts.values,
            names=risk_counts.index,
            title="Risk Level Distribution"
        )
        
        st.plotly_chart(fig_risk, use_container_width=True)
        
        # Urgency analysis
        st.subheader("üö® Urgency Analysis")
        
        urgency_data = [
            {"Material": rec.material_id.value, "Urgency": rec.urgency_score, "Lead Time": rec.expected_lead_time.days}
            for rec in recommendations
        ]
        
        urgency_df = pd.DataFrame(urgency_data)
        
        fig_urgency = px.scatter(
            urgency_df,
            x="Lead Time",
            y="Urgency",
            hover_data=["Material"],
            title="Urgency vs Lead Time Analysis",
            labels={"Lead Time": "Lead Time (days)", "Urgency": "Urgency Score"}
        )
        
        st.plotly_chart(fig_urgency, use_container_width=True)
    
    def show_recommendations_table(self, recommendations: List[ProcurementRecommendation]):
        """Display recommendations in a table format"""
        if not recommendations:
            st.info("No recommendations to display")
            return
        
        # Convert to DataFrame
        data = []
        for rec in recommendations:
            data.append({
                "Material ID": rec.material_id.value,
                "Supplier ID": rec.supplier_id.value,
                "Quantity": f"{rec.recommended_order_qty.amount} {rec.recommended_order_qty.unit}",
                "Unit Cost": f"${rec.unit_cost.amount:.2f}",
                "Total Cost": f"${rec.total_cost.amount:.2f}",
                "Lead Time": f"{rec.expected_lead_time.days} days",
                "Risk": rec.risk_flag.value,
                "Urgency": f"{rec.urgency_score:.2f}",
                "Reasoning": rec.reasoning
            })
        
        df = pd.DataFrame(data)
        
        # Style the dataframe
        def highlight_risk(val):
            if val == "HIGH":
                return 'background-color: #ffcccb'
            elif val == "MEDIUM":
                return 'background-color: #ffffcc'
            else:
                return 'background-color: #ccffcc'
        
        styled_df = df.style.applymap(highlight_risk, subset=['Risk'])
        
        st.dataframe(styled_df, use_container_width=True)
    
    def run_data_integration(self):
        """Run the data integration process"""
        with st.spinner("Running data integration..."):
            try:
                domain_objects = self.data_integrator.integrate_live_data()
                st.session_state.domain_objects = domain_objects
                st.session_state.data_loaded = True
                st.success("‚úÖ Data integration completed successfully!")
                
                # Show summary
                st.subheader("Integration Summary")
                for key, objects in domain_objects.items():
                    st.write(f"- {key.title()}: {len(objects)} items")
                
            except Exception as e:
                st.error(f"‚ùå Data integration failed: {str(e)}")
                logger.error(f"Data integration error: {e}")
    
    def run_planning_engine(self):
        """Run the planning engine"""
        with st.spinner("Running planning engine..."):
            try:
                domain_objects = st.session_state.domain_objects
                
                recommendations = self.planning_engine.execute_planning_cycle(
                    forecasts=domain_objects.get('forecasts', []),
                    boms=domain_objects.get('boms', []),
                    inventory=domain_objects.get('inventory', []),
                    suppliers=domain_objects.get('supplier_materials', [])
                )
                
                st.session_state.recommendations = recommendations
                st.success(f"‚úÖ Planning completed! Generated {len(recommendations)} recommendations.")
                
            except Exception as e:
                st.error(f"‚ùå Planning failed: {str(e)}")
                logger.error(f"Planning error: {e}")
    
    def run_sales_based_planning(self):
        """Run sales-based planning engine"""
        with st.spinner("Running sales-based planning engine..."):
            try:
                domain_objects = st.session_state.domain_objects
                
                # Check if sales data is available
                sales_data = getattr(self.data_integrator, 'sales_data', None)
                style_bom_data = getattr(self.data_integrator, 'style_bom_data', None)
                
                if sales_data is None or style_bom_data is None:
                    st.warning("‚ö†Ô∏è Sales data not available. Please ensure sales and BOM data are loaded.")
                    return
                
                recommendations = self.planning_engine.execute_sales_based_planning_cycle(
                    sales_data=sales_data,
                    style_bom_data=style_bom_data,
                    inventory=domain_objects.get('inventory', []),
                    suppliers=domain_objects.get('supplier_materials', [])
                )
                
                st.session_state.recommendations = recommendations
                st.success(f"‚úÖ Sales-based planning completed! Generated {len(recommendations)} recommendations.")
                
                # Show additional sales insights
                st.subheader("üìä Sales-Based Insights")
                st.info("Sales-based planning uses historical sales patterns to generate more accurate demand forecasts.")
                
            except Exception as e:
                st.error(f"‚ùå Sales-based planning failed: {str(e)}")
                logger.error(f"Sales-based planning error: {e}")
    
    def show_quality_report(self):
        """Display data quality report"""
        st.subheader("üìã Data Quality Report")
        
        # This would read from the actual quality report file
        st.markdown("""
        **Data Quality Summary:**
        - ‚úÖ Negative inventory balances automatically corrected
        - ‚úÖ BOM percentages normalized
        - ‚úÖ Cost data formatting cleaned
        - ‚ö†Ô∏è Some materials missing supplier assignments
        - ‚ö†Ô∏è Zero-cost items require pricing data
        """)
    
    def export_recommendations_csv(self, recommendations: List[ProcurementRecommendation]):
        """Export recommendations to CSV"""
        # Implementation for CSV export
        st.success("üìÑ Recommendations exported to CSV")
    
    def export_recommendations_excel(self, recommendations: List[ProcurementRecommendation]):
        """Export recommendations to Excel"""
        # Implementation for Excel export
        st.success("üìä Recommendations exported to Excel")
    
    def generate_executive_report(self):
        """Generate executive summary report"""
        st.subheader("üìä Executive Summary Report")
        
        if not st.session_state.recommendations:
            st.info("No recommendations available for report generation")
            return
        
        recommendations = st.session_state.recommendations
        
        # Summary metrics
        total_cost = sum(rec.total_cost.amount for rec in recommendations)
        high_risk_count = sum(1 for rec in recommendations if rec.risk_flag.value == "HIGH")
        avg_lead_time = sum(rec.expected_lead_time.days for rec in recommendations) / len(recommendations)
        
        st.markdown(f"""
        **Executive Summary - Beverly Knits Supply Chain Planning**
        
        **Key Metrics:**
        - Total Procurement Value: ${total_cost:,.2f}
        - Materials Requiring Procurement: {len(recommendations)}
        - High-Risk Suppliers: {high_risk_count}
        - Average Lead Time: {avg_lead_time:.1f} days
        
        **Recommendations:**
        - Execute procurement plan for {len(recommendations)} materials
        - Focus on high-risk suppliers for contingency planning
        - Monitor lead times for potential delays
        """)
    
    def show_simple_dashboard(self):
        """Show a simplified dashboard when imports are not available"""
        import os
        from pathlib import Path
        
        st.header("üìä Data Overview (Limited Mode)")
        
        # Check data directory
        data_path = Path("data/live")
        
        if data_path.exists():
            st.success("‚úÖ Live data directory found!")
            
            # List files
            csv_files = list(data_path.glob("*.csv"))
            
            if csv_files:
                st.subheader("üìÅ Available Data Files")
                
                for file in csv_files:
                    with st.expander(f"üìÑ {file.name}"):
                        try:
                            df = pd.read_csv(file, encoding='utf-8-sig')
                            st.write(f"**Rows:** {len(df)}, **Columns:** {len(df.columns)}")
                            st.write("**Columns:**", ", ".join(df.columns))
                            st.dataframe(df.head(), use_container_width=True)
                        except Exception as e:
                            st.error(f"Error reading file: {e}")
                            
                # Simple aggregated metrics
                st.subheader("üìà Quick Statistics")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("Total CSV Files", len(csv_files))
                
                with col2:
                    total_rows = 0
                    for file in csv_files:
                        try:
                            df = pd.read_csv(file, encoding='utf-8-sig')
                            total_rows += len(df)
                        except:
                            pass
                    st.metric("Total Data Rows", total_rows)
                    
            else:
                st.warning("No CSV files found in data/live directory")
        else:
            st.error("‚ùå Live data directory not found")
        
        st.info("üîÑ Restart the application to reload modules or check for missing dependencies.")
    
    def run_ml_forecasting(self, periods: int, models: List[str], ensemble_method: str, confidence_threshold: float):
        """Run ML forecasting using production models"""
        with st.spinner("Generating ML forecasts using trained models..."):
            try:
                # Use actual sales data for forecasting
                data_integrator = BeverlyKnitsLiveDataIntegrator(data_path="data/live/")
                
                # Load sales data
                sales_path = Path("data/live/Sales Activity Report.csv")
                if sales_path.exists():
                    sales_data = pd.read_csv(sales_path, encoding='utf-8-sig')
                    
                    # Prepare historical data
                    sales_data['Invoice Date'] = pd.to_datetime(sales_data['Invoice Date'])
                    sales_data['Yds_ordered'] = pd.to_numeric(sales_data['Yds_ordered'], errors='coerce')
                    sales_data['Unit Price'] = sales_data['Unit Price'].str.replace('$', '').str.replace(',', '')
                    sales_data['Unit Price'] = pd.to_numeric(sales_data['Unit Price'], errors='coerce')
                    
                    # Create daily aggregated data
                    daily_data = sales_data.groupby('Invoice Date').agg({
                        'Yds_ordered': 'sum',
                        'Unit Price': 'mean',
                        'Document': 'count'
                    }).reset_index()
                    
                    # Fill missing dates and prepare features
                    date_range = pd.date_range(
                        start=daily_data['Invoice Date'].min(),
                        end=daily_data['Invoice Date'].max(),
                        freq='D'
                    )
                    
                    daily_data = daily_data.set_index('Invoice Date')
                    daily_data = daily_data.reindex(date_range, fill_value=0)
                    daily_data = daily_data.rename(columns={'Yds_ordered': 'demand'})
                    
                    # Use production ML loader
                    predictions = production_ml_loader.predict_demand(daily_data, periods=periods)
                    
                    # Convert to domain forecasts
                    domain_forecasts = []
                    for pred in predictions:
                        forecast = Forecast(
                            sku_id=SkuId(value="aggregate"),
                            forecast_qty=Quantity(amount=pred['predicted_demand'], unit="yards"),
                            forecast_date=pred['date'].date(),
                            source=ForecastSource.PROJECTION,
                            confidence_score=pred['confidence'],
                            created_at=datetime.now()
                        )
                        domain_forecasts.append(forecast)
                    
                    st.session_state.ml_forecasts = {
                        'forecasts': domain_forecasts,
                        'raw_predictions': predictions,
                        'models_used': ['random_forest'],
                        'ensemble_method': ensemble_method,
                        'confidence_threshold': confidence_threshold,
                        'data_source': 'beverly_knits_sales'
                    }
                    
                    st.success(f"‚úÖ ML forecasts generated! {len(domain_forecasts)} forecasts created using trained models on real Beverly Knits data.")
                    
                    # Show model performance
                    model_status = production_ml_loader.get_model_status()
                    if 'model_details' in model_status:
                        st.info(f"üìä Model Performance: {model_status['model_details']}")
                    
                else:
                    st.error("Sales data not found. Please ensure data is loaded.")
                    
            except Exception as e:
                st.error(f"‚ùå ML forecasting failed: {str(e)}")
                logger.error(f"ML forecasting error: {e}")
    
    def run_ml_risk_assessment(self, risk_threshold_low: float, risk_threshold_medium: float, anomaly_contamination: float, retrain_models: bool):
        """Run ML risk assessment using production models"""
        with st.spinner("Running ML risk assessment using trained models..."):
            try:
                # Load actual supplier data
                inventory_path = Path("data/live/Yarn_ID_Current_Inventory.csv")
                if inventory_path.exists():
                    inventory_data = pd.read_csv(inventory_path, encoding='utf-8-sig')
                    
                    # Prepare supplier data for risk assessment
                    supplier_data = pd.DataFrame()
                    
                    # Map inventory data to expected format
                    supplier_data['supplier_id'] = inventory_data['Supplier'].astype(str)
                    supplier_data['material_id'] = inventory_data['Yarn_ID'].astype(str)
                    
                    # Parse cost data
                    cost_data = inventory_data['Cost_Pound'].astype(str).str.replace('$', '').str.replace(',', '')
                    supplier_data['cost_per_unit'] = pd.to_numeric(cost_data, errors='coerce').fillna(0)
                    
                    # Parse inventory data
                    inventory_str = inventory_data['Inventory'].astype(str).str.replace(',', '').str.replace('(', '-').str.replace(')', '')
                    supplier_data['inventory_level'] = pd.to_numeric(inventory_str, errors='coerce').fillna(0)
                    
                    # Parse on-order data
                    on_order_str = inventory_data['On_Order'].astype(str).str.replace(',', '')
                    supplier_data['on_order'] = pd.to_numeric(on_order_str, errors='coerce').fillna(0)
                    
                    # Use production ML loader for anomaly detection
                    anomalies = production_ml_loader.detect_anomalies(supplier_data)
                    
                    # Calculate risk scores (simplified)
                    risk_scores = []
                    for _, row in supplier_data.iterrows():
                        # Simple risk scoring based on available data
                        cost_risk = min(row['cost_per_unit'] / 10.0, 1.0)  # Normalize cost
                        inventory_risk = 1.0 if row['inventory_level'] < 0 else 0.0
                        overall_risk = (cost_risk + inventory_risk) / 2.0
                        
                        risk_level = 'HIGH' if overall_risk > 0.7 else 'MEDIUM' if overall_risk > 0.3 else 'LOW'
                        
                        risk_scores.append({
                            'supplier_id': row['supplier_id'],
                            'material_id': row['material_id'],
                            'overall_risk': overall_risk,
                            'risk_level': risk_level,
                            'cost_risk': cost_risk,
                            'inventory_risk': inventory_risk
                        })
                    
                    st.session_state.ml_risk_assessment = {
                        'risk_assessment': {
                            'risk_scores': risk_scores,
                            'anomalies': anomalies
                        },
                        'thresholds': {
                            'low': risk_threshold_low,
                            'medium': risk_threshold_medium
                        },
                        'anomaly_contamination': anomaly_contamination,
                        'retrained': retrain_models,
                        'data_source': 'beverly_knits_inventory'
                    }
                    
                    high_risk_count = sum(1 for r in risk_scores if r['risk_level'] == 'HIGH')
                    anomaly_count = len(anomalies)
                    
                    st.success(f"‚úÖ Risk assessment completed! {len(risk_scores)} suppliers assessed, {high_risk_count} high-risk suppliers, {anomaly_count} anomalies detected.")
                    
                    # Show model performance
                    model_status = production_ml_loader.get_model_status()
                    if 'model_details' in model_status and 'anomaly_detection' in model_status['model_details']:
                        metrics = model_status['model_details']['anomaly_detection']
                        st.info(f"üìä Anomaly Detection: {metrics}")
                    
                else:
                    st.error("Inventory data not found. Please ensure data is loaded.")
                    
            except Exception as e:
                st.error(f"‚ùå Risk assessment failed: {str(e)}")
                logger.error(f"Risk assessment error: {e}")
    
    def run_ml_enhanced_planning(self, periods: int, models: List[str]):
        """Run ML-enhanced planning"""
        with st.spinner("Running ML-enhanced planning..."):
            try:
                # Generate sample data for demo
                import numpy as np
                
                # Historical demand data
                dates = pd.date_range(start='2023-01-01', periods=365, freq='D')
                demand = 100 + 50 * np.sin(np.arange(365) * 2 * np.pi / 365) + np.random.normal(0, 10, 365)
                
                historical_data = pd.DataFrame({
                    'date': dates,
                    'demand': demand
                })
                historical_data = historical_data.set_index('date')
                
                # Supplier data
                suppliers = ['SUP001', 'SUP002', 'SUP003', 'SUP004', 'SUP005']
                materials = ['MAT001', 'MAT002', 'MAT003', 'MAT004', 'MAT005']
                
                supplier_data = []
                for i in range(50):
                    supplier_data.append({
                        'supplier_id': np.random.choice(suppliers),
                        'material_id': np.random.choice(materials),
                        'cost_per_unit': np.random.uniform(10, 100),
                        'lead_time_days': np.random.randint(7, 45),
                        'moq_amount': np.random.randint(100, 1000),
                        'reliability_score': np.random.uniform(0.6, 1.0),
                        'quality_score': np.random.uniform(0.7, 1.0),
                        'created_at': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 365))
                    })
                
                supplier_df = pd.DataFrame(supplier_data)
                
                # Get domain objects from session state
                domain_objects = st.session_state.domain_objects
                
                # Run ML-enhanced planning
                recommendations = self.planning_engine.execute_ml_enhanced_planning_cycle(
                    historical_demand_data=historical_data,
                    supplier_data=supplier_df,
                    boms=domain_objects.get('boms', []),
                    inventory=domain_objects.get('inventory', []),
                    suppliers=domain_objects.get('supplier_materials', []),
                    periods=periods,
                    models=models
                )
                
                st.session_state.recommendations = recommendations
                st.success(f"‚úÖ ML-enhanced planning completed! Generated {len(recommendations)} recommendations with ML insights.")
                
            except Exception as e:
                st.error(f"‚ùå ML-enhanced planning failed: {str(e)}")
                logger.error(f"ML-enhanced planning error: {e}")
    
    def show_ml_forecast_results(self, ml_forecasts: Dict[str, Any]):
        """Display ML forecast results"""
        forecasts = ml_forecasts.get('forecasts', [])
        models_used = ml_forecasts.get('models_used', [])
        
        if not forecasts:
            st.info("No forecast results to display")
            return
        
        st.write(f"**Models Used:** {', '.join(models_used)}")
        st.write(f"**Forecasts Generated:** {len(forecasts)}")
        
        # Convert forecasts to DataFrame for display
        forecast_data = []
        for forecast in forecasts:
            forecast_data.append({
                'Date': forecast.forecast_date,
                'SKU': forecast.sku_id.value,
                'Quantity': forecast.forecast_qty.amount,
                'Confidence': forecast.confidence_score,
                'Source': forecast.source.value
            })
        
        forecast_df = pd.DataFrame(forecast_data)
        
        if not forecast_df.empty:
            # Display forecast chart
            fig = px.line(
                forecast_df,
                x='Date',
                y='Quantity',
                color='SKU',
                title='ML Demand Forecasts',
                labels={'Quantity': 'Forecast Quantity', 'Date': 'Date'}
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Display forecast table
            st.dataframe(forecast_df, use_container_width=True)
    
    def show_ml_risk_results(self, ml_risk_assessment: Dict[str, Any]):
        """Display ML risk assessment results"""
        risk_assessment = ml_risk_assessment.get('risk_assessment', {})
        risk_scores = risk_assessment.get('risk_scores', [])
        anomalies = risk_assessment.get('anomalies', [])
        
        if not risk_scores:
            st.info("No risk assessment results to display")
            return
        
        # Risk score summary
        col1, col2, col3 = st.columns(3)
        
        with col1:
            high_risk_count = sum(1 for score in risk_scores if score.risk_level.value == 'HIGH')
            st.metric("High Risk Suppliers", high_risk_count)
        
        with col2:
            medium_risk_count = sum(1 for score in risk_scores if score.risk_level.value == 'MEDIUM')
            st.metric("Medium Risk Suppliers", medium_risk_count)
        
        with col3:
            anomaly_count = sum(1 for anomaly in anomalies if anomaly.is_anomaly)
            st.metric("Anomalies Detected", anomaly_count)
        
        # Risk scores table
        risk_data = []
        for score in risk_scores:
            risk_data.append({
                'Supplier': getattr(score, 'supplier_id', 'Unknown'),
                'Overall Score': f"{score.overall_score:.2f}",
                'Financial Risk': f"{score.financial_risk:.2f}",
                'Operational Risk': f"{score.operational_risk:.2f}",
                'Quality Risk': f"{score.quality_risk:.2f}",
                'Delivery Risk': f"{score.delivery_risk:.2f}",
                'Risk Level': score.risk_level.value,
                'Confidence': f"{score.confidence:.2f}",
                'Factors': ', '.join(score.factors)
            })
        
        risk_df = pd.DataFrame(risk_data)
        
        if not risk_df.empty:
            # Risk distribution chart
            risk_counts = risk_df['Risk Level'].value_counts()
            fig = px.pie(
                values=risk_counts.values,
                names=risk_counts.index,
                title='Risk Level Distribution'
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Risk scores table
            st.dataframe(risk_df, use_container_width=True)
        
        # Anomalies table
        if anomalies:
            anomaly_data = []
            for anomaly in anomalies:
                if anomaly.is_anomaly:
                    anomaly_data.append({
                        'Supplier': getattr(anomaly, 'supplier_id', 'Unknown'),
                        'Anomaly Type': anomaly.anomaly_type,
                        'Severity': anomaly.severity,
                        'Score': f"{anomaly.anomaly_score:.2f}",
                        'Description': anomaly.description
                    })
            
            if anomaly_data:
                st.subheader("üö® Detected Anomalies")
                anomaly_df = pd.DataFrame(anomaly_data)
                st.dataframe(anomaly_df, use_container_width=True)

# Run the application
if __name__ == "__main__":
    app = BeverlyKnitsApp()
    app.run()